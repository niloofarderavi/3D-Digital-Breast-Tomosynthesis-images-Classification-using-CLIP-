# Install required packages
!pip install ftfy regex tqdm
!pip install git+https://github.com/openai/CLIP.git
!pip install imbalanced-learn
!pip install torchvision albumentations

import os
import clip
import torch
import numpy as np
from PIL import Image
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import (classification_report, confusion_matrix,
                           roc_auc_score, accuracy_score, roc_curve, auc,
                           balanced_accuracy_score, f1_score, precision_score, recall_score,
                           precision_recall_curve, average_precision_score)
from sklearn.preprocessing import label_binarize
import matplotlib.pyplot as plt
import seaborn as sns
import random
from collections import defaultdict, Counter
import torchvision.transforms as transforms
import albumentations as A
from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE
from imblearn.under_sampling import TomekLinks, NearMiss
from imblearn.combine import SMOTETomek, SMOTEENN
from imblearn.ensemble import BalancedRandomForestClassifier, RUSBoostClassifier
from imblearn.metrics import geometric_mean_score, specificity_score
from imblearn.pipeline import Pipeline

# Set device and seed for reproducibility
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")
RANDOM_STATE = 42
torch.manual_seed(RANDOM_STATE)
np.random.seed(RANDOM_STATE)
random.seed(RANDOM_STATE)

# Load CLIP model with larger architecture for better feature extraction
model, preprocess = clip.load("ViT-B/32", device=device)
print("CLIP model loaded successfully")

# Dataset path
dataset_path = "/root/.cache/kagglehub/datasets/gabrielcarvalho11/breast-cancer-screening-dbt/versions/1/Breast-Cancer-Screening-DBT"
classes = ['Benign', 'Actionable', 'Cancer', 'Normal']
class_to_idx = {cls: i for i, cls in enumerate(classes)}

# Enhanced medical text prompts with even more detailed BI-RADS descriptions
text_descriptions = [
    "A mammogram showing BI-RADS 2 benign findings with smooth, well-circumscribed margins, round or oval shape, and no suspicious features suggestive of malignancy",
    "A mammogram with BI-RADS 3 or 4 findings showing focal asymmetries, clustered microcalcifications, or architectural distortions requiring follow-up or biopsy",
    "A mammogram showing BI-RADS 5 or 6 malignant lesions with spiculated masses, irregular shapes, pleomorphic calcifications, or other highly suspicious features",
    "A completely normal BI-RADS 1 mammogram with symmetrical fibroglandular tissue, no masses, no calcifications, and no architectural distortions"
]
text_inputs = torch.cat([clip.tokenize(desc) for desc in text_descriptions]).to(device)

# Advanced augmentation strategy focusing on minority classes
def get_augmentations(minority_classes):
    return A.Compose([
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
        A.RandomRotate90(p=0.5),
        A.RandomBrightnessContrast(p=0.5),
        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=30, p=0.5),
        A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),
        A.GaussianBlur(blur_limit=(3, 7), p=0.3),
        A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),
        A.GridDistortion(p=0.3),
        A.OpticalDistortion(distort_limit=0.3, shift_limit=0.3, p=0.3),
    ])

# Function to extract CLIP features with custom preprocessing
def extract_features(image_path, augment=False, minority_classes=None):
    try:
        image = Image.open(image_path).convert("RGB")
        image_np = np.array(image)
        
        # Apply augmentations to minority classes
        if augment and minority_classes is not None:
            class_name = os.path.basename(os.path.dirname(image_path))
            if class_name in minority_classes:
                augmentations = get_augmentations(minority_classes)
                augmented = augmentations(image=image_np)
                image_np = augmented["image"]
                image = Image.fromarray(image_np)
        
        image_input = preprocess(image).unsqueeze(0).to(device)
        with torch.no_grad():
            image_features = model.encode_image(image_input)
        return image_features.cpu().numpy()
    except Exception as e:
        print(f"Error processing {image_path}: {str(e)}")
        return None

# Collect all image paths and labels with detailed analysis
def collect_dataset(dataset_path, classes):
    image_paths = []
    labels = []
    class_counts = {cls: 0 for cls in classes}
    
    for class_name in classes:
        class_dir = os.path.join(dataset_path, class_name)
        images = [img for img in os.listdir(class_dir) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]
        class_counts[class_name] = len(images)
        
        for img_name in images:
            image_paths.append(os.path.join(class_dir, img_name))
            labels.append(class_to_idx[class_name])
    
    # Identify minority and majority classes
    sorted_classes = sorted(class_counts.items(), key=lambda x: x[1])
    minority_classes = [cls for cls, count in sorted_classes[:2]]  # Two smallest classes
    majority_class = sorted_classes[-1][0]  # Largest class
    
    imbalance_ratio = class_counts[majority_class] / class_counts[minority_classes[0]]
    
    print(f"\nTotal images collected: {len(image_paths)}")
    print(f"Class distribution: {class_counts}")
    print(f"Minority classes: {minority_classes}")
    print(f"Majority class: {majority_class}")
    print(f"Imbalance ratio (majority:minority): {imbalance_ratio:.2f}:1")
    
    # Visualize class distribution
    plt.figure(figsize=(10, 6))
    sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()))
    plt.title("Class Distribution in Original Dataset")
    plt.ylabel("Number of samples")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
    
    return image_paths, labels, minority_classes, majority_class, class_counts

# Collect dataset with analysis
image_paths, labels, minority_classes, majority_class, class_counts = collect_dataset(dataset_path, classes)

# Enhanced feature extraction strategy
def process_dataset_features(image_paths, labels, minority_classes=None):
    features = []
    processed_labels = []
    
    print("Extracting features for all images...")
    for i, (path, label) in enumerate(zip(image_paths, labels)):
        if (i+1) % 100 == 0:
            print(f"Processed {i+1}/{len(image_paths)} images")
            
        # Extract features with augmentation for minority classes
        feat = extract_features(path, augment=(path in minority_classes), minority_classes=minority_classes)
        if feat is not None:
            features.append(feat.flatten())
            processed_labels.append(label)
    
    return np.array(features), np.array(processed_labels)

# Advanced resampling strategy tailored to severe imbalance
def create_balanced_dataset(features, labels, minority_classes, resampling_strategy='combined'):
    print(f"\nApplying {resampling_strategy} resampling strategy...")
    
    # Create appropriate resampling pipeline based on strategy
    if resampling_strategy == 'smote':
        resampler = SMOTE(sampling_strategy='auto', random_state=RANDOM_STATE, k_neighbors=min(5, min(Counter(labels).values())-1))
    elif resampling_strategy == 'adasyn':
        resampler = ADASYN(sampling_strategy='auto', random_state=RANDOM_STATE, n_neighbors=min(5, min(Counter(labels).values())-1))
    elif resampling_strategy == 'borderline':
        resampler = BorderlineSMOTE(sampling_strategy='auto', random_state=RANDOM_STATE, k_neighbors=min(5, min(Counter(labels).values())-1))
    elif resampling_strategy == 'combined':
        # SMOTE + Tomek Links to create borderline examples and clean majority class
        resampler = SMOTETomek(sampling_strategy='auto', random_state=RANDOM_STATE, 
                            smote=SMOTE(k_neighbors=min(5, min(Counter(labels).values())-1)))
    else:
        # Default to combined approach
        resampler = SMOTETomek(sampling_strategy='auto', random_state=RANDOM_STATE)
    
    # Apply resampling
    X_resampled, y_resampled = resampler.fit_resample(features, labels)
    
    # Analyze resampled distribution
    resampled_counts = Counter(y_resampled)
    class_names = {v: k for k, v in class_to_idx.items()}
    resampled_class_counts = {class_names[label]: count for label, count in resampled_counts.items()}
    
    print(f"Original class distribution: {Counter(labels)}")
    print(f"Resampled class distribution: {resampled_counts}")
    
    # Visualize resampling effect
    plt.figure(figsize=(12, 6))
    
    plt.subplot(1, 2, 1)
    sns.barplot(x=[class_names[i] for i in sorted(Counter(labels).keys())], 
                y=[Counter(labels)[i] for i in sorted(Counter(labels).keys())])
    plt.title("Original Class Distribution")
    plt.ylabel("Number of samples")
    plt.xticks(rotation=45)
    
    plt.subplot(1, 2, 2)
    sns.barplot(x=[class_names[i] for i in sorted(resampled_counts.keys())], 
                y=[resampled_counts[i] for i in sorted(resampled_counts.keys())])
    plt.title(f"Resampled Class Distribution ({resampling_strategy})")
    plt.ylabel("Number of samples")
    plt.xticks(rotation=45)
    
    plt.tight_layout()
    plt.show()
    
    return X_resampled, y_resampled

# Extract features for all images
features, processed_labels = process_dataset_features(image_paths, labels, minority_classes)

# Apply advanced resampling
X_resampled, y_resampled = create_balanced_dataset(features, processed_labels, minority_classes, 'combined')

# Create stratified train/validation splits
X_train, X_val, y_train, y_val = train_test_split(
    X_resampled, y_resampled, test_size=0.2, random_state=RANDOM_STATE, stratify=y_resampled
)

# Implement Focal Loss for imbalanced classification
class FocalLoss(torch.nn.Module):
    def __init__(self, alpha=None, gamma=2):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        
    def forward(self, inputs, targets):
        BCE_loss = torch.nn.functional.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-BCE_loss)
        F_loss = (1 - pt) ** self.gamma * BCE_loss
        
        if self.alpha is not None:
            F_loss = self.alpha[targets] * F_loss
            
        return torch.mean(F_loss)

# Create a PyTorch dataset and dataloader for training
class MammogramDataset(torch.utils.data.Dataset):
    def __init__(self, features, labels):
        self.features = torch.tensor(features, dtype=torch.float32)
        self.labels = torch.tensor(labels, dtype=torch.long)
        
    def __len__(self):
        return len(self.labels)
    
    def __getitem__(self, idx):
        return self.features[idx], self.labels[idx]

# Create a simple MLP classifier
class MLPClassifier(torch.nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(MLPClassifier, self).__init__()
        self.fc1 = torch.nn.Linear(input_size, hidden_size)
        self.bn1 = torch.nn.BatchNorm1d(hidden_size)
        self.fc2 = torch.nn.Linear(hidden_size, hidden_size // 2)
        self.bn2 = torch.nn.BatchNorm1d(hidden_size // 2)
        self.fc3 = torch.nn.Linear(hidden_size // 2, num_classes)
        self.dropout = torch.nn.Dropout(0.5)
        
    def forward(self, x):
        x = torch.nn.functional.relu(self.bn1(self.fc1(x)))
        x = self.dropout(x)
        x = torch.nn.functional.relu(self.bn2(self.fc2(x)))
        x = self.dropout(x)
        x = self.fc3(x)
        return x

# Calculate class weights for weighted loss
def calculate_class_weights(labels, beta=0.999, use_effective_number=True):
    class_counts = np.bincount(labels)
    if use_effective_number:
        # Effective Number of Samples (ENS) weighting
        effective_num = 1.0 - np.power(beta, class_counts)
        weights = (1.0 - beta) / (effective_num + 1e-8)
    else:
        # Inverse frequency weighting
        weights = 1.0 / (class_counts + 1e-8)
    
    # Normalize weights
    weights = weights / weights.sum() * len(class_counts)
    return weights

# Enhanced prediction function with calibration
def predict_with_classifier(model, features, temperature=1.0):
    model.eval()
    features_tensor = torch.tensor(features, dtype=torch.float32).to(device)
    
    with torch.no_grad():
        logits = model(features_tensor)
        # Apply temperature scaling for calibration
        scaled_logits = logits / temperature
        probs = torch.nn.functional.softmax(scaled_logits, dim=1)
    
    return probs.cpu().numpy()

# Comprehensive evaluation function
def evaluate_classifier(model, X, y, set_name="Validation"):
    probs = predict_with_classifier(model, X)
    preds = np.argmax(probs, axis=1)
    
    # Calculate standard metrics
    metrics = {
        'accuracy': accuracy_score(y, preds),
        'balanced_accuracy': balanced_accuracy_score(y, preds),
        'macro_f1': f1_score(y, preds, average='macro'),
        'weighted_f1': f1_score(y, preds, average='weighted'),
        'macro_precision': precision_score(y, preds, average='macro'),
        'macro_recall': recall_score(y, preds, average='macro'),
        # Add imbalanced metrics
        'geometric_mean': geometric_mean_score(y, preds, average='macro'),
    }
    
    # Calculate per-class metrics
    for i, cls in enumerate(classes):
        metrics[f'{cls}_precision'] = precision_score(y, preds, labels=[i], average=None)[0]
        metrics[f'{cls}_recall'] = recall_score(y, preds, labels=[i], average=None)[0]
        metrics[f'{cls}_f1'] = f1_score(y, preds, labels=[i], average=None)[0]
        # For specificity in multiclass, we need to compute it manually or use a different approach
        # as specificity_score doesn't work directly with multiclass
        
    # Calculate AUC for each class
    y_true_bin = label_binarize(y, classes=range(len(classes)))
    auc_scores = []
    
    for i, cls in enumerate(classes):
        auc_score = roc_auc_score(y_true_bin[:, i], probs[:, i])
        auc_scores.append(auc_score)
        metrics[f'{cls}_auc'] = auc_score
    
    metrics['macro_auc'] = np.mean(auc_scores)
    
    # Plot normalized confusion matrix (if not in final evaluation mode)
    if set_name != "Final":
        plt.figure(figsize=(10, 8))
        cm = confusion_matrix(y, preds)
        cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100
        
        sns.heatmap(cm_percent, annot=True, fmt='.1f', cmap='Blues',
                    xticklabels=classes,
                    yticklabels=classes,
                    vmin=0, vmax=100)
        plt.title(f'Normalized Confusion Matrix (%)\n{set_name} Set')
        plt.xlabel('Predicted')
        plt.ylabel('True')
        plt.tight_layout()
        plt.show()
        
        # Plot ROC and PR curves for all classes
        plt.figure(figsize=(15, 6))
        
        # ROC Curves
        plt.subplot(1, 2, 1)
        for i, cls in enumerate(classes):
            fpr, tpr, _ = roc_curve(y_true_bin[:, i], probs[:, i])
            roc_auc = auc(fpr, tpr)
            plt.plot(fpr, tpr, label=f'{cls} (AUC = {roc_auc:.2f})')
        
        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title(f'{set_name} Set ROC Curves')
        plt.legend(loc="lower right")
        
        # Precision-Recall Curves
        plt.subplot(1, 2, 2)
        for i, cls in enumerate(classes):
            precision, recall, _ = precision_recall_curve(y_true_bin[:, i], probs[:, i])
            ap = average_precision_score(y_true_bin[:, i], probs[:, i])
            plt.plot(recall, precision, label=f'{cls} (AP = {ap:.2f})')
        
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title(f'{set_name} Set Precision-Recall Curves')
        plt.legend(loc="best")
        
        plt.tight_layout()
        plt.show()
    
    return metrics, preds, probs

# Train the classifier with focal loss
def train_classifier(X_train, y_train, X_val, y_val, num_epochs=30):
    # Create datasets and dataloaders
    train_dataset = MammogramDataset(X_train, y_train)
    val_dataset = MammogramDataset(X_val, y_val)
    
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)
    
    # Initialize model
    input_size = X_train.shape[1]
    hidden_size = 256
    num_classes = len(classes)
    model = MLPClassifier(input_size, hidden_size, num_classes).to(device)
    
    # Calculate class weights for focal loss
    class_weights = calculate_class_weights(y_train, beta=0.999, use_effective_number=True)
    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)
    
    # Use Focal Loss for imbalanced classification
    criterion = FocalLoss(alpha=class_weights_tensor, gamma=2.0)
    
    # Use Adam optimizer with cosine annealing
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)
    
    # Training loop
    best_val_loss = float('inf')
    best_model_state = None
    train_losses = []
    val_losses = []
    
    print("\nTraining classifier...")
    for epoch in range(num_epochs):
        model.train()
        train_loss = 0.0
        
        for features, targets in train_loader:
            features, targets = features.to(device), targets.to(device)
            
            # Zero gradients
            optimizer.zero_grad()
            
            # Forward pass
            outputs = model(features)
            loss = criterion(outputs, targets)
            
            # Backward pass and optimize
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
        
        # Update learning rate
        scheduler.step()
        
        # Validate
        model.eval()
        val_loss = 0.0
        
        with torch.no_grad():
            for features, targets in val_loader:
                features, targets = features.to(device), targets.to(device)
                outputs = model(features)
                loss = criterion(outputs, targets)
                val_loss += loss.item()
        
        # Calculate average losses
        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        train_losses.append(avg_train_loss)
        val_losses.append(avg_val_loss)
        
        # Save best model
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            best_model_state = model.state_dict().copy()
        
        # Print progress
        if (epoch + 1) % 5 == 0 or epoch == 0:
            print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}")
    
    # Load best model
    model.load_state_dict(best_model_state)
    
    # Plot training curves
    plt.figure(figsize=(10, 5))
    plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')
    plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()
    
    return model

# Create and train classifier
model = train_classifier(X_train, y_train, X_val, y_val, num_epochs=50)

# Evaluate on both sets
print("\nEvaluating classifier...")
train_metrics, train_preds, train_probs = evaluate_classifier(model, X_train, y_train, "Training")
val_metrics, val_preds, val_probs = evaluate_classifier(model, X_val, y_val, "Validation")

# Print metrics in a clean format
def print_metrics(metrics, set_name):
    print(f"\n{set_name} Set Metrics:")
    print(f"Accuracy: {metrics['accuracy']:.4f}")
    print(f"Balanced Accuracy: {metrics['balanced_accuracy']:.4f}")
    print(f"Macro F1: {metrics['macro_f1']:.4f}")
    print(f"Macro Precision: {metrics['macro_precision']:.4f}")
    print(f"Macro Recall: {metrics['macro_recall']:.4f}")
    print(f"Macro AUC: {metrics['macro_auc']:.4f}")
    print(f"Geometric Mean: {metrics['geometric_mean']:.4f}")

    print("\nPer-class metrics:")
    for cls in classes:
        print(f"\n{cls}:")
        print(f"  Precision: {metrics[f'{cls}_precision']:.4f}")
        print(f"  Recall: {metrics[f'{cls}_recall']:.4f}")
        print(f"  F1: {metrics[f'{cls}_f1']:.4f}")
        print(f"  AUC: {metrics[f'{cls}_auc']:.4f}")

# Create and train classifier
model = train_classifier(X_train, y_train, X_val, y_val, num_epochs=30)

# Evaluate on both sets
print("\nEvaluating classifier...")
train_metrics, train_preds, train_probs = evaluate_classifier(model, X_train, y_train, "Final")
val_metrics, val_preds, val_probs = evaluate_classifier(model, X_val, y_val, "Final")

print_metrics(train_metrics, "Training")
print_metrics(val_metrics, "Validation")

# Add a detailed summary of the most important metrics
print("\n=== FINAL PERFORMANCE SUMMARY ===")
print(f"Overall Accuracy: {val_metrics['accuracy']:.4f}")
print(f"Balanced Accuracy: {val_metrics['balanced_accuracy']:.4f}")
print(f"Macro F1 Score: {val_metrics['macro_f1']:.4f}")
print(f"Macro AUC: {val_metrics['macro_auc']:.4f}")
print(f"Macro Recall: {val_metrics['macro_recall']:.4f}")

print("\nPer-Class Performance:")
for cls in classes:
    print(f"{cls}: F1={val_metrics[f'{cls}_f1']:.4f}, AUC={val_metrics[f'{cls}_auc']:.4f}, Recall={val_metrics[f'{cls}_recall']:.4f}")

# Create a final confusion matrix visualization
plt.figure(figsize=(10, 8))
cm = confusion_matrix(y_val, val_preds)
cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100

sns.heatmap(cm_percent, annot=True, fmt='.1f', cmap='Blues',
            xticklabels=classes,
            yticklabels=classes,
            vmin=0, vmax=100)
plt.title('Final Validation Set Confusion Matrix (%)')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.tight_layout()
plt.show()

# Highlight performance on minority classes
print("\nMinority Class Performance Analysis:")
for cls in minority_classes:
    cls_idx = class_to_idx[cls]
    precision = val_metrics[f'{cls}_precision']
    recall = val_metrics[f'{cls}_recall']
    f1 = val_metrics[f'{cls}_f1']
    auc = val_metrics[f'{cls}_auc']
    
    print(f"\n{cls} class:")
    print(f"  Precision: {precision:.4f}")
    print(f"  Recall: {recall:.4f}")
    print(f"  F1-score: {f1:.4f}")
    print(f"  AUC: {auc:.4f}")

print("\n------------")
print("KEY IMPROVEMENTS FOR IMBALANCED DATASET:")
print("1. Used advanced resampling (SMOTETomek) to handle imbalance")
print("2. Implemented Focal Loss which naturally handles class imbalance")
print("3. Added extra augmentation for minority classes")
print("4. Used effective number sampling for better class weighting")
print("5. Implemented a PyTorch classifier with batch normalization and dropout")